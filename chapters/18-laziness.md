# Ледачість

Пам'ятаєте, в розділі про перші питання про Haskell я згадував, що ця мова є ледачою? Зараз ми нарешті дізнаємося про ледачі обчислення та познайомимося з їхніми світлою і темною сторонами.

## Дві моделі обчислень

Як ми вже знаємо, Haskell-програма складається з виразів, а запуск програми це початок довгого ланцюжка обчислень. Згадаймо функцію `square`, яка підносить свій єдиний аргумент до квадрату:

```haskell
main :: IO ()
main = print . square $ 4
```

Тут все просто: функція `square` застосовується до нередукованого виразу `4` і дає нам `16`. А якщо так:

```haskell
main :: IO ()
main = print . square $ 2 + 2
```

Тепер функція `square` застосовується вже до редукованого виразу:

```haskell
square  $              2 + 2

функція застосовується редукованого
        до             виразу
```

Як ви думаєте, що станеться раніше? Застосування оператора додавання чи застосування функції `square`? Питання хитре, адже правильної відповіді на нього немає, оскільки існує дві моделі обчислення аргументів, а саме енергійна (англ. eager) і ледача (англ. lazy).

При енергійній моделі (яку також називають &laquo;жадібною&raquo; чи &laquo;строгою&raquo;) вираз, що є аргументом функції, буде обчислено ще до того, як він потрапить у тіло функції. На тлі визначення функції `square` буде зрозуміліне:

```haskell
square     x   = x * x
         /   \ 
square $ 2 + 2
         \   /
           4   = 4 * 4 = 16
```

Тобто бачимо вираз `2 + 2`, жадібно на нього накидуємося, повністю обчислюємо, а вже потім результат цього обчислення передаємо в функцію `square`.

При ледачій моделі все навпаки: вираз, що є аргументом функції, передається у функцію прямо так, без обчислення. Зобразити це можна наступним чином:

```haskell
square     x =      x    *    x
         /   \    /   \     /   \
square $ 2 + 2 = (2 + 2) * (2 + 2) = 16
```

Але яка різниця, запитаєте ви? Все одно в підсумку отримаємо `16`, хоч там додаємо, хоч тут. Так і є: модель обчислення не впливає на результат цього обчислення, але вона впливає на дорогу до цього результату.

Жадібна модель знайшла своє втілення практично у всіх сучасних мовах програмування. Напишемо на C:

```c
#include <stdio.h>

int strange(int i) {
    return 22;
}

int main() {
    printf("%d\n", strange(2 / 0));
}
```

Функція `strange` дійсно дивна, адже вона ігнорує свій аргумент та просто повертає число `22`. Та все таки при запуску цієї програми ви гарантовано отримаєте помилку `Floating point exception`, бо компілятор мови C категорично не терпить ділення на нуль. А все тому, що мова C дотримується енергійної моделі обчислень: оператор ділення `2` на `0` буде викликаний ще до того, як ми увійдемо в тіло функції `strange`, тому програма впаде.

Такий підхід прямолінійний і строгий: нам спочатку наказали поділити на нуль &mdash; поділимо, не замислюючись. Ледача ж модель дотримується іншого підходу. Погляньте на Haskell-варіант:

```haskell
strange :: Int -> Int
strange i = 22

main :: IO ()
main = print . strange $ 2 `div` 0
```

Дивно, але при запуску цієї програми ми побачимо:

```bash
22
```

Втім, чому дивно? Функція `strange`, проігнорувавши свій аргумент, повернула нам значення `22`, яке, потрапивши на вхід функції `print`, потрапило в наш термінал. Але де ж помилка ділення `2` на `0`, запитаєте ви? Її немає.

Ледачий підхід цілком гармонує зі своєю назвою: нам ліньки робити роботу одразу. Замість цього ми, подібно дитині, яку змусили прибрати розкидані по кімнаті іграшки, відкладаємо роботу до останнього. Ледача модель гарантує, що робота буде виконана лише тоді, коли результат цієї роботи комусь знадобиться. Якщо ж він нікому не знадобиться, тоді робота не буде виконана.

Функція `strange` ледача, а тому раціональна. Вона дивиться на свій аргумент `i`:

```haskell
strange i = 22
```

і розуміє, що він ніде не використовується в її тілі. Значить, він не потрібен. А якщо так, то й обчисленим він не буде. До речі, якщо аргумент функції ігнорується, визначення прийнято писати з універсальним зразком:

```haskell
strange _ = 22

        ^
        нам
        все
        одно
```

Так і виходить:

```haskell
strange       _     = 22
          /       \
strange $ 2 `div` 0 = 22
```

Вираз, що містить ділення на нуль, потрапляє всередину функції, будучи ще необчисленим, але оскільки в тілі функції він ніде не використовується, він так і залишиться необчисленим. Девіз лінощів: якщо результат роботи нікому не потрібен &mdash; навіщо ж його робити? Ось чому фактичного ділення на нуль тут не відбудеться і програма не впаде.

Зрозуміло, якщо б ми визначили функцію `square` інакше:

```haskell
strange :: Int -> Int
strange i = i + 1
```

тоді інша справа: значення аргумента вже використовується в тілі функції, а значить обчислення аргумента неодмінно відбудеться:

```haskell
strange       i     =      i      + 1
          /       \    /       \
strange $ 2 `div` 0 = (2 `div` 0) + 1
```

Оператору додавання потрібні значення обох його аргументів, в тому числі лівого, а отже ви отримаєте помилку ділення на нуль.

## Якомога менше

Доки результат обчислення нікому не потрібен, воно не проводиться. Проте навіть тоді, коли результат комусь знадобився, обчислення відбувається не до кінця. Пам'ятаєте, вище я сказав, що при жадібній моделі обчислення вираз, що є аргументом, обчислюється &laquo;повністю&raquo;? А ось при ледачій моделі ми обчислюємо вираз лише настільки, наскільки це є необхідним. Так само як згадана раніше дитина, прибираючи іграшки в кімнаті, прибирає їх зовсім не до кінця, а лише до такої міри, щоб її не лаяли батьки.

З точки зору обчислення будь-який вираз в Haskell проходить через три стадії:

1. необчислений,
2. обчислений не до кінця,
3. обчислений до кінця.

Необчисленим називається такий вираз, який взагалі не чіпали. Згадаймо вищезазначене ділення на нуль:

```haskell
2 `div` 0
```

Ми побачили, що програма не впала, і це каже нам про те, що ділення не було. Тобто функція `div` так і не була застосована до своїх аргументів. Взагалі. Такий вислів називають thunk (можна перекласти як &laquo;задумка&raquo;). Тобто ми задумали застосувати функцію `div` до `2` і `0`, приготувалися зробити це &mdash; але в підсумку так і не зробили.

Обчисленим до кінця називають такий вираз, який обчислений до своєї остаточної, нередукованої форми. Про такий вираз кажуть як про вираз в &laquo;нормальній формі&raquo; (англ. normal form).

А ось обчисленим не до кінця називають такий вираз, що почали обчислювати, але зробили це не до кінця, тобто не до нормальної форми, а до так званої &laquo;слабкої головної форми&raquo; (англ. Weak Head Normal Form, WHNF). Ви запитаєте, як же це можна обчислити вираз не до кінця? Розглянемо приклад:

```haskell
main :: IO ()
main =
  let cx = 2 / 6.054 -- thunk
      nk = 4 * 12.003 -- thunk
      coeffs = [cx, nk] -- thunk
  in putStrLn "Nothing..."
```

В нас є два коефіцієнти, `cx` та `nk`, і ще список `coeffs`, в який ми помістили ці коефіцієнти. Але, як ми бачимо, у результаті ні ці коефіцієнти, ні цей список нам не знадобилися: ми просто вивели рядок і тихо вийшли. У цьому випадку жоден з цих виразів так і не було обчислено, вони залишились у вигляді thunk. Тобто оператор ділення так і не був застосований до `2` та `6.054`, оператор множення не торкнувся ні `4`, ні `12.003`, а список залишився лише в наших головах. Лінива стратегія раціональна: навіщо витрачати комп'ютерні ресурси на створення того, що в підсумку нікому не знадобиться?

Змінимо код:

```haskell
main :: IO ()
main =
  let cx = 2 / 6.054 -- thunk
      nk = 4 * 12.003 -- thunk
      coeffs = [cx, nk] -- WHNF
  in print $ length coeffs
```

Ага, вже цікавіше. Цього разу нам захотілося дізнатися довжину списку `coeffs`. У цьому випадку нам уже не обійтися без списку, інакше як же ми дізнаємося його довжину? Однак фокус в тому, що вираз `[cx, nk]` обчислюється не до кінця, а лише до тієї своєї форми, яка задовільнить функцію `length`.

Замислимося: функція `length` повертає кількість елементів списку, але яке їй діло до вмісту цих елементів? Зовсім ніякого. Тому в даному випадку список формується з thunk-ів:

```haskell
coeffs = [thunk, thunk]
```

Першим елементом списку є thunk, асоційований з необчисленим виразом `2 / 6.054`, а другим елементом списку є thunk, асоційований з необчисленим виразом `4 * 12.003`. Фактично, список `coeffs` вийшов би не зовсім справжнім: він би був сформованим в пам'яті як коректний список, однак всередині обох його елементів &mdash; вакуум. Все таки навіть така його форма цілком підходить для функції `length`, яка й так прекрасно зрозуміє, що у списку є два елементи. Про такий список говорять як про вираз в слабкій головний формі.

Ще трохи змінимо код:

```haskell
main :: IO ()
main =
  let cx = 2 / 6.054 -- thunk
      nk = 4 * 12.003 -- normal
      coeffs = [cx, nk] -- WHNF
  in print $ coeffs !! 1
```

Незвичний оператор `!!` дістає зі списку елемент за індексом, у даному випадку нас цікавить другий за порядком елемент. Тепер для нас вже недостатньо просто сформувати список, нам дійсно потрібен його другий елемент, інакше як би ми змогли вивести його на консоль? У цьому випадку вираз `4 * 12.003` буде обчислено до своєї остаточної, нормальної форми, а результат цього обчислення стане другим елементом списку, ось так:

```haskell
coeffs = [thunk, 48.012]
```

Однак перший елемент списку так і залишився непотрібним, тому вираз `2 / 6.054` залишається не більше ніж нашою задумкою. В цьому випадку список `coeffs` все одно залишається у слабкій головній формі, адже всередині першого елемента все ще вакуум.

А тепер напишемо так:

```haskell
main :: IO ()
main =
  let cx = 2 / 6.054 -- normal
      nk = 4 * 12.003 -- normal
      coeffs = [cx, nk] -- normal
  in print coeffs
```

Ось, тепер ніяких лінощів. Список `coeffs` повинен бути виведеним на консоль повністю, а отже, обидва його елементи повинні бути обчислені до своєї нормальної форми, інакше ми не змогли б показати їх у консолі.

Ось філософія ледачої стратегії: навіть якщо нам потрібно обчислити вираз, ми обчислюємо його лише до тієї форми, яка є достатньою в конкретних умовах, і не більше.

## Раціональність

Як вже було згадано, ледача стратегія допомагає програмі бути раціональною та не робити зайву роботу. Розглянемо приклад:

```haskell
main :: IO ()
main = print $ take 5 evens
  where evens = [2, 4 .. 100]
```

Список `evens`, який формується через арифметичну послідовність, містить у собі парні числа від `2` до `100` включно. Використовується цей список в якості другого аргумента функції `take`, яка дає нам N перших елементів з переданого їй списку:

```haskell
take   5         evens

візьми лише
       п'ять
       елементів з цього
                 списку
```

При запуску цієї програми ми отримаємо очікуваний результат:

```bash
[2,4,6,8,10]
```

У чому ж тут раціональність, запитаєте ви? А в тому, що список `evens` в результаті містив у собі лише 5 елементів. Так, але ж парних чисел від `2` до `100` набагато більше, ніж п'ять! Абсолютно вірно, але ледачість дозволяє нам зробити лише стільки роботи, скільки реально потрібно. Оскільки список `evens` потрібен лише функції `take`, яка, в свою чергу, хоче тільки п'ять перших його елементів &mdash; навіщо ж створювати елементи, які залишилися? Потрібно перші п'ять &mdash; отримай п'ять. Якщо ж напишемо так:

```haskell
main :: IO ()
main = print $ take 50 evens
  where evens = [2, 4 .. 100]
```

тоді у списку `evens` виявиться вже п'ятдесят елементів, тому що саме стільки потрібно функції `take`. Повторю філософію ледачого раціоналізму: зробимо не стільки, скільки нам сказали, а лише стільки, скільки дійсно знадобиться.

## Нескінченність

А що буде, якщо ми візьмемо зі списку `evens` 500 елементів? Ось так:

```haskell
main :: IO ()
main = print $ take 500 evens
  where evens = [2, 4 .. 100]
```

Нічого страшного не трапиться, функція `take` перевіряє вихід за границі і у випадку, якщо її перший аргумент перевищує довжину списку, вона просто повертає нам той же список. Так, але ж ми хочемо побачити п'ятсот парних чисел, а не п'ятдесят! Можна було б збільшити список:

```haskell
main :: IO ()
main = print $ take 500 evens
  where evens = [2, 4 .. 100000]
```

але це ненадійно, адже потім знову може знадобитися ще більше. Потрібно щось універсальне, і в Haskell є відповідне рішення:

```haskell
main :: IO ()
main = print $ take 500 evens
  where evens = [2, 4 ..] -- Що це?
```

Тепер не сумнівайтеся: у списку `evens` буде не менше ніж п'ятисот парних чисел. Але що це за така конструкція? Початок дано, крок даний, а де ж кінець? Познайомтеся, це нескінченний список:

```haskell
[2, 4 ..]
```

Ледача модель обчислень дозволяє нам працювати з нескінченними структурами даних. Ось прямо так, починаючи з двійки й, з кроком через один, йдемо в нескінченну далечінь... Жартую. Насправді, список вийде зовсім не нескінченним, а настільки великим, наскільки нам це знадобиться.

Й справді, якщо функція `take` вимагає від нас N елементів &mdash; навіщо нам взагалі задавати закінчення діапазону списку? Все одно в ньому буде не більше ніж N. Нескінченна структура даних тим і корисна, що з неї завжди можна взяти стільки, скільки потрібно.

Звичайно, якщо б ми вирішили похуліганити:

```haskell
main :: IO ()
main = print evens -- Дай нам все!
  where evens = [2, 4 ..]
```

у цьому випадку в нашу консоль швидко посипалося б дуже багато чисел...

## Space leak

Так, я повинен розповісти вам правду: є у ледачої стратегії обчислень темна сторона, що отримала назву space leak (букв. &laquo;витік простору&raquo;). І ось в чому її суть.

Згадаймо приклад з діленням:

```haskell
main :: IO ()
main = print . strange $ 2 `div` 0
```

Як ми пам'ятаємо, ділення на нуль, так і не відбулося через непотрібність його результату. В цьому випадку вираз залишився у вигляді thunk. Виникає питання: що ж з ним сталось? У нас є функція `div` і є два значення типу `Int`, `2` та `0`. Якщо функція `div` так і не була застосована до них, де все це знаходилося в процесі роботи нашої програми? Воно знаходилося в пам'яті, у вигляді особливого графа, який можна зобразити так:

```haskell
┌─────────────┐
│ div │   │   │
└─────────────┘
        │   │
        v   v
     ┌───┐ ┌───┐
     │ 2 │ │ 0 │
     └───┘ └───┘
```

Тобто сама функція та два значення, які повинні були зайняти місце двох аргументів. І ось цей граф в пам'яті так і залишився незатребуваним. Здавалося б, в чому проблема? А проблема в кількості. Якщо ми змогли написати код, при роботі якого в пам'ять відклався один thunk, значить, теоретично, ми можемо написати і такий код, кількість thunk-ів при роботі якого буде обчислюватися мільйонами. А враховуючи той факт, що кожен thunk займає в пам'яті хоча б декілька байт, ви можете собі уявити масштаб проблеми.

Причому ця проблема може виникнути з вельми безневинного на перший погляд коду:

```haskell
bad :: [Int] -> Int -> Int
bad [] c = c
bad (_:others) c = bad others $ c + 1
```

Простенька рекурсивна функція, яка пробігає по непотрібному їй списку і збільшує свій другий аргумент на одиницю. Але я не просто так назвав її `bad`. Давайте застосуємо її:

```haskell
bad [1, 2, 3] 0
```

Підставимо у визначення, яке містить зациклення:

```haskell
bad (_: others) c = bad others $ c + 1

bad [1, 2, 3]   0 = bad [2, 3] $ 0 + 1

        ____              ______

                =                =
```

&laquo;Голова&raquo; списку відкидається і ігнорується, а до `0` додається `1`. Але оскільки результат додавання поки що нікому не потрібен, додавання не виконується. Замість цього, на другій ітерації, ми бачимо наступне:

```haskell
bad [2, 3] $ 0 + 1 = bad [3] $ (0 + 1) + 1
```

До попереднього виразу знову додається одиниця &mdash; й ми знову входимо в чергову ітерацію, так і не виконавши додавання:

```haskell
bad [3] $ (0 + 1) + 1 = bad [] $ ((0 + 1) + 1) + 1
```

Отакої! Зупинилися на порожньому списку, згадуємо правило виходу з рекурсії:

```haskell
bad [] c = c
```

Отже, у цьому випадку ми просто повертаємо значення другого аргументу. Зробимо це:

```haskell
bad [] $ ((0 + 1) + 1) + 1 = ((0 + 1) + 1) + 1 = 3
```

І ось тільки тут ми реально обчислюємо другий аргумент, складаючи три одиниці. Ви запитаєте, чому ж ми накопичували ці додавання замість того, щоб робити їх відразу? Тому що ми ледачі: якщо результат додавання знадобився нам лише на останній ітерації, значить до цієї ітерації ніякого додавання не буде, адже ледачість змушує нас відкладати роботу до кінця.

Ось у цьому накопиченні і полягає вся біда. Уявімо, що ми написали так:

```haskell
main :: IO ()
main = print $ bad [1..50000000] 0
```

50 мільйонів елементів, а значить, 50 мільйонів разів додавання другого аргументу з одиницею буде відкладатися, накопичуючи гігантський &laquo;хвіст&raquo; з (поки що) необчислених виразів. Хочете знати, що станеться при запуску такої програми? Її виконання, на MacBook Pro 2014 року, займе приблизно 63 секунди і з'їсть 6.4 ГБ пам'яті! А тепер уявіть, що сталося б, якби елементів у списку було не 50 мільйонів, а 50 мільярдів...

Іноді space leak помилково плутають з іншою проблемою, яка називається memory leak (англ. &laquo;витік пам'яті&raquo;), проте це зовсім не одне і те ж. Витік пам'яті &mdash; це помилка, характерна для мов з ручним керуванням пам'яттю, наприклад, C. Якщо ми виділимо пам'ять в купі (англ. heap), а потім втратимо вказівник, що зв'язує нас з цією пам'яттю &mdash; все, виділена пам'ять втекла, вона втрачена для нас навіки. Але у випадку space leak ми не втрачаємо пам'ять: коли весь цей &laquo;хвіст&raquo; з додавань зрештою обчислиться, пам'ять, зайнята мільйонами thunk-ів, звільниться. Ми не втрачаємо пам'ять, ми просто використовуємо її занадто багато.

## Боротьба

Проблема space leak випливає з самої природи ледачих обчислень. Багато програмістів, дізнавшись про цю проблему, відвертаються від Haskell. Мовляв, якщо в цій мові можна легко написати код, який споживає купу пам'яті, значить ця мова точно не підходить для серйозного використання. Але не такий страшний чорт, як його малюють. Я розповім про два способи боротьби зі space leak.

Втім, з концептуальної точки зору спосіб всього один. Замислимося: якщо в наведеному вище прикладі ледачість стала причиною відкладання додавань на потім, що ж можна зробити? Відповідь проста: ми повинні прибрати зайву ледачість та замінити її строгістю. У цьому випадку застосування оператора додавання вже не буде відкладатися до останнього, а буде проводитися тут же, як в мовах зі строгою моделлю обчислень.

І як же ми можемо розбавити лінь строгістю? Ось два способи.

### Оптимізація

Перший спосіб найпростіший &mdash; оптимізація. Коли компілятор перетворює наш код у програму, його можна попросити оптимізувати наш код, зробивши його більш ефективним, згідно тих чи інших критеріїв. Щоб попросити компілятор провести оптимізацію, ми повинні використовувати спеціальний параметр компілятора. Відкриємо збірочний файл нашого проекту `real.cabal`, знайдемо секцію `executable real-exe`, в якій є рядок:

```haskell
ghc-options: ...
```

Цей рядок містить різні опції компілятора GHC, і оптимізаційний параметр дописується саме сюди. Спробуємо підставити туди спочатку параметр `-O0`, а потім `-O2`. Результати запуску програми будуть такими:

```bash
Оптимізація Час    Пам'ять

-O0         63 c   6,4 ГБ

-O2         3.2 с  104 кБ
```
Вражаюча різниця, чи не так? Параметр `-O0` наказує компілятору не робити ніякої оптимізації, в цьому випадку кажуть про нульовий рівень оптимізації. Параметр `-O2`, навпаки, встановлює стандартний для production-проектів рівень оптимізації. Так от при стандартному рівні компілятор здатний розпізнати зайву ледачість в нашому коді і додати трохи жадібності. У прикладі вище компілятор побачить накопичення thunk-ів додавання та припинить його. Погодьтеся, з гігабайтів стрибнути відразу на кілобайти &mdash; це круто.

Так що, проблеми немає? Ну, якщо оптимізація `-O2` й так стандартна &mdash; то давайте ставити її в наші проекти і забудемо про space leak! На жаль, не все так просто.

По-перше, компіляторна оптимізація це щось на кшталт чорної магії, на неї важко покладатися. Ми дуже вдячні компілятору GHC за спробу допомогти нам, але ця допомога не завжди відповідає нашим очікуванням. По-друге, на жаль, компілятор не завжди здатний розпізнати зайву ледачість в нашому коді, і в цьому випадку нам доводиться вдаватися до другого способу боротьби зі space leak.

### Вручну

Повернемося до визначення функції `bad`:

```haskell
bad :: [Int] -> Int -> Int
bad [] c = c
bad (_:others) c = bad others $ c + 1
```

Проблема, як ми вже зрозуміли, у другому аргументі:

```haskell
bad others $ c + 1

             накопичення
             thunk-ів...
```

Перетворимо злу функцію в добру:

```haskell
good :: [Int] -> Int -> Int
good [] c = c
good (_:others) c = good others $! c + 1
```

Цей код дасть нам приблизно такий же виграш, як оптимізація рівня `-O2`: секунди замість хвилин і кілобайти замість гігабайтів. Що ж змінилося? Дивимося уважно:

```haskell
good others $! c + 1

             ^
```

Замість звичного оператора застосування `$` ми бачимо оператор строгого застосування `$!` (англ. strict application operator). Цей оператор каже аргументу: &laquo;Забудь про лінощі, я наказую тобі негайно обчислитися до слабкої головної форми&raquo;:

```haskell
good others $!      c + 1

                    обчисли цей
                    аргумент

            строго,
            а не
            ледаче!
```

Тому наш &laquo;хвіст&raquo; з thunk-ів й не буде накопичуватися, адже на кожній з 50 мільйонів ітерацій буде відбуватися негайне застосування оператора додавання. Таким чином, змусити аргумент тут же обчислитися до слабкої головної або нормальної форми можна як за допомогою того, що цей аргумент прямо зараз комусь знадобився, так і за допомогою строгого застосування.

## Ледачість і строгість разом

Функцію називають ледачою по тих аргументах, які не обчислюються, та строгою по тих аргументах, які обчислюються. Примітивний приклад:

```haskell
fakeSum :: Int -> Int -> Int
fakeSum x _ = x + 100
```

Функція `fakeSum` строга по своєму першому аргументу і лінива по своєму другому аргументу. Перший аргумент `x` неодмінно буде обчислюватися, адже він передається оператору додавання. Другий аргумент ігнорується, залишившись необчисленим. До речі, існує простий спосіб перевірити, строга функція по деякому аргументу або ледача.

У стандартній бібліотеці Haskell визначена особлива функція `undefined`. Це &mdash; чорна діра: при спробі доторкнутися до неї програма гарантовано падає з помилкою. Перевіряємо:

```haskell
main :: IO ()
main = print $ fakeSum 1 undefined
```

В цьому випадку ми отримаємо результат:

```bash
101
```

Чорна діра була проігнорована, адже функція `fakeSum` ледача по другому аргументу. Якщо ж ми напишемо так:

```haskell
main :: IO ()
main = print $ fakeSum undefined 45
```

програма, спробувавши передати `undefined` оператору додавання, аварійно зупиниться. Або ось інший приклад:

```haskell
main :: IO ()
main = print . head $ [23, undefined, undefined]
```

Не сумнівайтеся: програма спокійно поверне нам `23`, адже функція `head` строга лише по першому елементу переданого їй списку, інший його вміст її абсолютно не цікавить. Але якщо спробуєте витягнути другий або третій елемент з цього списку &mdash; крах неминучий.

## Для допитливих

Haskell &mdash; не перша мову з ледачою стратегією обчислень. Відкрию вам історичний факт: у мови Haskell був попередник, мова програмування з красивим жіночим ім'ям [Miranda](https://en.wikipedia.org/wiki/Miranda_(programming_language)). Ледачість і чиста функціональність прийшли в Haskell саме з Miranda, і лише у цих двох мовах ледача стратегія обчислення аргументів використовується за замовчуванням. На сьогоднішній день, наскільки мені відомо, мова Miranda мертва. Втім, як суто дослідницька мова вона, можливо, кимось і використовується.

Що ж стосується проблеми space leak, то на щастя, існують способи виявлення функцій, які є ненажерливими до пам'яті. Справді, уявіть собі великий проект, тисячі функцій, і щось їсть гігабайти пам'яті. Як знайти винного? Цей процес ще називають &laquo;space leak профілюванням&raquo;. Розповідати про це тут я не стану, матеріал досить об'ємний. Але для особливо цікавих наводжу посилання на непогану англомовну статтю на тему: [Chasing a Space Leak in Shake](http://neilmitchell.blogspot.am/2013/02/chasing-space-leak-in-shake.html).

І ще пригадаймо ось це:

```haskell
square     x   =       x    *    x
         /   \       /   \     /   \
square $ 2 + 2 =     (2 + 2) * (2 + 2) = 16

         обчислюємо  і що,
                     знову
                     обчислюємо?!
```

Уважний читач здивується, мовляв, невже вираз `2 + 2` обчислюється двічі?! Адже це нераціонально. Звичайно нераціонально, тому в реальності воно буде обчислено один раз. В Haskell є особливий механізм &laquo;шарінгу&raquo; (англ. sharing), що дозволяє уникнути марної роботи. Якщо у нас є декілька однакових виразів, то їх обчислення відбувається один раз, а результат зберігається та потім просто підставляється в потрібні місця. Наприклад:

```haskell
main :: IO ()
main =
  let x = sin 2 in print x * x
```

Якби не sharing-механізм, функція `sin` була б застосована до `2` двічі. На щастя, значення синуса буде обчислено раз і тут же збережено, щоб потім просто стати на місця тих двох `x`.